{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Sarsa 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 사용할 패키지 임포트하기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 초기 상태의 미로 모습\n",
    "\n",
    "# 전체 그림의 크기 및 그림을 나타내는 변수 선언\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 붉은 벽 그리기\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 상태를 의미하는 문자열(S0~S8) 표시\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 그림을 그릴 범위 및 눈금 제거 설정\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# S0에 녹색 원으로 현재 위치를 표시\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Policy 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책을 결정하는 파라미터의 초깃값 theta_0를 설정\n",
    "\n",
    "# 줄은 상태 0~7, 열은 행동방향(상,우,하,좌 순)를 나타낸다\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8은 목표지점이므로 정책이 없다\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Policy :\n",
      " [[0.         0.5        0.5        0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.5        0.5        0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 정책 파라미터 theta_0을 무작위 행동 정책 pi로 변환하는 함수\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''단순 비율 계산'''\n",
    "\n",
    "    [m, n] = theta.shape  # theta의 행렬 크기를 구함\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 비율 계산\n",
    "\n",
    "    pi = np.nan_to_num(pi)  # nan을 0으로 변환\n",
    "\n",
    "    return pi\n",
    "\n",
    "# 무작위 행동정책 pi_0을 계산\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)\n",
    "\n",
    "print(\"Initial Policy :\\n\", pi_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Q-table 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Q-table is randomly created :\n",
      " [[       nan 0.46945124 0.57002848        nan]\n",
      " [       nan 0.07291225        nan 0.78837759]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.87089504        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4871742         nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "# 행동가치 함수 Q의 초기 상태\n",
    "\n",
    "[a, b] = theta_0.shape  # 열과 행의 갯수를 변수 a, b에 저장\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta0 로 요소 단위 곱셈을 수행, Q에서 벽 방향으로 이동하는 행동에는 nan을 부여\n",
    "\n",
    "print(\"Initial Q-table is randomly created :\\n\", Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function - get_action, get_s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε-greedy 알고리즘 구현\n",
    "\n",
    "\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "    # 행동을 결정\n",
    "    if np.random.rand() < epsilon:\n",
    "        # 확률 ε로 무작위 행동을 선택함\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # Q값이 최대가 되는 행동을 선택함\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 행동을 인덱스로 변환\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_s_next(s, a):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a]  # 행동 a의 방향\n",
    "\n",
    "    # 행동으로 다음 상태를 결정\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3  # 위로 이동하면 상태값이 3 줄어든다\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1  # 오른쪽으로 이동하면 상태값이 1 늘어난다\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3  # 아래로 이동하면 상태값이 3 늘어난다\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1  # 왼쪽으로 이동하면 상태값이 1 줄어든다\n",
    "\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-table 업데이트 with Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 행동가치 함수 Q를 수정\n",
    "\n",
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "\n",
    "    if s_next == 8:  # 목표 지점에 도달한 경우\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "\n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 미로를 빠져나오는 함수, 상태 및 행동 그리고 Q값의 히스토리를 출력한다\n",
    "\n",
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi, episode):\n",
    "    s = 0  # 시작 지점\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 첫 번째 행동\n",
    "    s_a_history = [[0, np.nan]]  # 에이전트의 행동 및 상태의 히스토리를 기록하는 리스트\n",
    "\n",
    "    while (1):  # 목표 지점에 이를 때까지 반복\n",
    "        a = a_next  # 행동 결정\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 현재 상태(마지막이므로 인덱스가 -1)을 히스토리에 추가\n",
    "\n",
    "        s_next = get_s_next(s, a)\n",
    "        # 다음 단계의 상태를 구함\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 다음 상태를 히스토리에 추가, 행동은 아직 알 수 없으므로 nan으로 둔다\n",
    "\n",
    "        # 보상을 부여하고 다음 행동을 계산함\n",
    "        if s_next == 8:\n",
    "            r = 1  # 목표 지점에 도달했다면 보상을 부여\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 다음 행동 a_next를 계산\n",
    "\n",
    "        # 가치함수를 수정\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "        if episode == 1:\n",
    "            print(\"Q-table :\\n\", Q)\n",
    "        \n",
    "        # 종료 여부 판정\n",
    "        if s_next == 8:  # 목표 지점에 도달하면 종료\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run N episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드: 1\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.57002848        nan]\n",
      " [       nan 0.07291225        nan 0.78837759]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.87089504        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4871742         nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.57002848        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.87089504        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4871742         nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.87089504        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4871742         nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.82765121        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4871742         nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.82765121        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.51294539        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.79105118        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.51294539        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.79105118        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53284545        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.75990215        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53284545        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57677352 0.75990215        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53147053        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57832085 0.75990215        nan]\n",
      " [       nan        nan 0.65805209 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53147053        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57832085 0.75990215        nan]\n",
      " [       nan        nan 0.62051012 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53147053        nan        nan        nan]\n",
      " [0.88721221 0.31403595        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57832085 0.75990215        nan]\n",
      " [       nan        nan 0.62051012 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53147053        nan        nan        nan]\n",
      " [0.88721221 0.38263236        nan        nan]]\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.59140618        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.45013277 0.57832085 0.75990215        nan]\n",
      " [       nan        nan 0.62051012 0.65432924]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.53147053        nan        nan        nan]\n",
      " [0.88721221 0.38263236        nan        nan]]\n",
      "0.20792497191405845\n",
      "목표 지점에 이르기까지 걸린 단계 수는 12단계입니다\n",
      "에피소드: 2\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.57233758        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.47851717 0.51609456 0.51792445        nan]\n",
      " [       nan        nan 0.49557831 0.515921  ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.50898017        nan        nan        nan]\n",
      " [0.51081288 0.44436912        nan        nan]]\n",
      "0.7983442256555682\n",
      "목표 지점에 이르기까지 걸린 단계 수는 158단계입니다\n",
      "에피소드: 3\n",
      "Q-table :\n",
      " [[       nan 0.4934601  0.51044121        nan]\n",
      " [       nan 0.07291225        nan 0.76084239]\n",
      " [       nan        nan 0.02975473 0.11721753]\n",
      " [0.48067262 0.47590324 0.47930576        nan]\n",
      " [       nan        nan 0.4719679  0.47846934]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4760778         nan        nan        nan]\n",
      " [0.48605713 0.49993221        nan        nan]]\n",
      "0.18038289539701063\n",
      "목표 지점에 이르기까지 걸린 단계 수는 50단계입니다\n",
      "에피소드: 4\n",
      "Q-table :\n",
      " [[       nan 0.43821147 0.46641759        nan]\n",
      " [       nan 0.08235169        nan 0.51235662]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.46348752 0.46263166 0.46431907        nan]\n",
      " [       nan        nan 0.46976501 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.46220019        nan        nan        nan]\n",
      " [0.48605713 0.54993899        nan        nan]]\n",
      "0.4491598615030573\n",
      "목표 지점에 이르기까지 걸린 단계 수는 68단계입니다\n",
      "에피소드: 5\n",
      "Q-table :\n",
      " [[       nan 0.43821147 0.45704494        nan]\n",
      " [       nan 0.08235169        nan 0.51235662]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.45867958 0.45864734 0.45948518        nan]\n",
      " [       nan        nan 0.47228302 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.45769405        nan        nan        nan]\n",
      " [0.48605713 0.59494509        nan        nan]]\n",
      "0.06623678927721999\n",
      "목표 지점에 이르기까지 걸린 단계 수는 8단계입니다\n",
      "에피소드: 6\n",
      "Q-table :\n",
      " [[       nan 0.43821147 0.44870296        nan]\n",
      " [       nan 0.08235169        nan 0.51235662]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.45355409 0.45528808 0.45472913        nan]\n",
      " [       nan        nan 0.47859977 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4532058         nan        nan        nan]\n",
      " [0.48605713 0.63545058        nan        nan]]\n",
      "0.06384957265160351\n",
      "목표 지점에 이르기까지 걸린 단계 수는 8단계입니다\n",
      "에피소드: 7\n",
      "Q-table :\n",
      " [[       nan 0.43821147 0.44480859        nan]\n",
      " [       nan 0.08235169        nan 0.51235662]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.45355409 0.45283325 0.45472913        nan]\n",
      " [       nan        nan 0.48793035 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.4532058         nan        nan        nan]\n",
      " [0.48605713 0.67190552        nan        nan]]\n",
      "0.05023883557908854\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 8\n",
      "Q-table :\n",
      " [[       nan 0.43821147 0.43788301        nan]\n",
      " [       nan 0.08235169        nan 0.51235662]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.45146366 0.45004474        nan]\n",
      " [       nan        nan 0.49960881 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.70471497        nan        nan]]\n",
      "0.05885121433400381\n",
      "목표 지점에 이르기까지 걸린 단계 수는 8단계입니다\n",
      "에피소드: 9\n",
      "Q-table :\n",
      " [[       nan 0.43706148 0.43472644        nan]\n",
      " [       nan 0.08235169        nan 0.45783916]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.45128208 0.45004474        nan]\n",
      " [       nan        nan 0.51307228 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.73424347        nan        nan]]\n",
      "0.09884099192739038\n",
      "목표 지점에 이르기까지 걸린 단계 수는 16단계입니다\n",
      "에피소드: 10\n",
      "Q-table :\n",
      " [[       nan 0.43456086 0.43186918        nan]\n",
      " [       nan 0.08235169        nan 0.45118063]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.45233038 0.45004474        nan]\n",
      " [       nan        nan 0.52784696 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.76081913        nan        nan]]\n",
      "0.05155779402243499\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 11\n",
      "Q-table :\n",
      " [[       nan 0.43171103 0.429392          nan]\n",
      " [       nan 0.08235169        nan 0.44493079]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.45460357 0.45004474        nan]\n",
      " [       nan        nan 0.54353599 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.78473721        nan        nan]]\n",
      "0.05097996639730812\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 12\n",
      "Q-table :\n",
      " [[       nan 0.4285837  0.42736712        nan]\n",
      " [       nan 0.08235169        nan 0.43908299]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.45806145 0.45004474        nan]\n",
      " [       nan        nan 0.55980874 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.80626349        nan        nan]]\n",
      "0.05023204172005036\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 13\n",
      "Q-table :\n",
      " [[       nan 0.4252428  0.42585594        nan]\n",
      " [       nan 0.08235169        nan 0.43363773]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.46263809 0.45004474        nan]\n",
      " [       nan        nan 0.57639158 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.82563714        nan        nan]]\n",
      "0.04870614698002845\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 14\n",
      "Q-table :\n",
      " [[       nan 0.4252428  0.42490777        nan]\n",
      " [       nan 0.08235169        nan 0.43363773]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.46824953 0.45004474        nan]\n",
      " [       nan        nan 0.59305976 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.84307343        nan        nan]]\n",
      "0.04032904776683943\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 15\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.42455945        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.47479995 0.45004474        nan]\n",
      " [       nan        nan 0.6096304  0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.85876609        nan        nan]]\n",
      "0.044619130912416316\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 16\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.4248355         nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.48218669 0.45004474        nan]\n",
      " [       nan        nan 0.6259563  0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.87288948        nan        nan]]\n",
      "0.03811209028876833\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 17\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.42574876        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.49030409 0.45004474        nan]\n",
      " [       nan        nan 0.64192073 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.88560053        nan        nan]]\n",
      "0.037706124865780455\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 18\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.42730125        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.49904655 0.45004474        nan]\n",
      " [       nan        nan 0.6574327  0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.89704048        nan        nan]]\n",
      "0.037246870951528566\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 19\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.42948531        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.50831083 0.45004474        nan]\n",
      " [       nan        nan 0.67242307 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.90733643        nan        nan]]\n",
      "0.036734677918174474\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 20\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.43228476        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.51799783 0.45004474        nan]\n",
      " [       nan        nan 0.68684104 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.91660279        nan        nan]]\n",
      "0.036170765351154266\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 21\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.43567609        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.52801374 0.45004474        nan]\n",
      " [       nan        nan 0.70065119 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.92494251        nan        nan]]\n",
      "0.035557107752046124\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 22\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.43962971        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.53827097 0.45004474        nan]\n",
      " [       nan        nan 0.7138309  0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.93244826        nan        nan]]\n",
      "0.03489631707885549\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 23\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.44411113        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.54868866 0.45004474        nan]\n",
      " [       nan        nan 0.72636815 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.93920343        nan        nan]]\n",
      "0.034191527390786625\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 24\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.449082          nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.55919292 0.45004474        nan]\n",
      " [       nan        nan 0.73825964 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.94528309        nan        nan]]\n",
      "0.033446284661669046\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 25\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.45450116        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.569717   0.45004474        nan]\n",
      " [       nan        nan 0.74950916 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.95075478        nan        nan]]\n",
      "0.03266444386860984\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 26\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.46032557        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.58020112 0.45004474        nan]\n",
      " [       nan        nan 0.76012617 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.9556793         nan        nan]]\n",
      "0.03185007470738144\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 27\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.46651112        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.59059237 0.45004474        nan]\n",
      " [       nan        nan 0.77012469 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.96011137        nan        nan]]\n",
      "0.031007376697460565\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 28\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.47301332        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.60084435 0.45004474        nan]\n",
      " [       nan        nan 0.77952225 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.96410023        nan        nan]]\n",
      "0.030140603987329984\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 29\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.47978798        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.61091692 0.45004474        nan]\n",
      " [       nan        nan 0.78833904 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.96769021        nan        nan]]\n",
      "0.02925399982925847\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 30\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.4867917         nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.62077574 0.45004474        nan]\n",
      " [       nan        nan 0.79659726 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.97092119        nan        nan]]\n",
      "0.0283517404411891\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 31\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.49398235        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.63039192 0.45004474        nan]\n",
      " [       nan        nan 0.80432044 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.97382907        nan        nan]]\n",
      "0.027437887793934912\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 32\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.50131939        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.63974157 0.45004474        nan]\n",
      " [       nan        nan 0.81153301 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.97644616        nan        nan]]\n",
      "0.026516350740017125\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 33\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.50876419        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.64880538 0.45004474        nan]\n",
      " [       nan        nan 0.81825986 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.97880155        nan        nan]]\n",
      "0.02559085382406867\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 34\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.51628026        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.65756823 0.45004474        nan]\n",
      " [       nan        nan 0.82452602 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.98092139        nan        nan]]\n",
      "0.024664913073814687\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 35\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.52383337        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.66601875 0.45004474        nan]\n",
      " [       nan        nan 0.83035634 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.98282925        nan        nan]]\n",
      "0.02374181805704767\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 36\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.53139172        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.67414895 0.45004474        nan]\n",
      " [       nan        nan 0.83577534 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.98454633        nan        nan]]\n",
      "0.02282461949709169\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 37\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.53892595        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.68195383 0.45004474        nan]\n",
      " [       nan        nan 0.84080698 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.9860917         nan        nan]]\n",
      "0.021916121761550222\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 38\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.5464092         nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.68943108 0.45004474        nan]\n",
      " [       nan        nan 0.84547453 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.98748253        nan        nan]]\n",
      "0.021018879572336613\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 39\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.55381708        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.69658068 0.45004474        nan]\n",
      " [       nan        nan 0.8498005  0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.98873427        nan        nan]]\n",
      "0.020135198325568315\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 40\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.56112763        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.70340465 0.45004474        nan]\n",
      " [       nan        nan 0.85380654 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.98986085        nan        nan]]\n",
      "0.019267137455128203\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 41\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.56832129        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.70990678 0.45004474        nan]\n",
      " [       nan        nan 0.85751336 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99087476        nan        nan]]\n",
      "0.01841651632137986\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 42\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.57538077        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.7160923  0.45004474        nan]\n",
      " [       nan        nan 0.86094075 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99178729        nan        nan]]\n",
      "0.017584922154992078\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 43\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.582291          nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.72196774 0.45004474        nan]\n",
      " [       nan        nan 0.86410753 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99260856        nan        nan]]\n",
      "0.01677371963381369\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 44\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.589039          nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.72754064 0.45004474        nan]\n",
      " [       nan        nan 0.86703155 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.9933477         nan        nan]]\n",
      "0.0159840617173016\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 45\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.59561375        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.73281942 0.45004474        nan]\n",
      " [       nan        nan 0.86972969 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99401293        nan        nan]]\n",
      "0.015216901407451022\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 46\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.60200613        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.73781315 0.45004474        nan]\n",
      " [       nan        nan 0.87221788 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99461164        nan        nan]]\n",
      "0.014473004147048218\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 47\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.6082087         nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.74253144 0.45004474        nan]\n",
      " [       nan        nan 0.87451114 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99515047        nan        nan]]\n",
      "0.013752960605067921\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 48\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.61421566        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.7469843  0.45004474        nan]\n",
      " [       nan        nan 0.87662357 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99563543        nan        nan]]\n",
      "0.013057199634995853\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 49\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.62002268        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.75118199 0.45004474        nan]\n",
      " [       nan        nan 0.8785684  0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.99607188        nan        nan]]\n",
      "0.012386001224719001\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 50\n",
      "Q-table :\n",
      " [[       nan 0.42174591 0.62562679        nan]\n",
      " [       nan 0.08235169        nan 0.42851566]\n",
      " [       nan        nan 0.02975473 0.18492573]\n",
      " [0.44791148 0.75513495 0.45004474        nan]\n",
      " [       nan        nan 0.88035803 0.4682384 ]\n",
      " [0.51714996        nan        nan        nan]\n",
      " [0.44870509        nan        nan        nan]\n",
      " [0.48605713 0.9964647         nan        nan]]\n",
      "0.01173950928640799\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n"
     ]
    }
   ],
   "source": [
    "# Sarsa 알고리즘으로 미로 빠져나오기\n",
    "\n",
    "eta = 0.1  # 학습률\n",
    "gamma = 0.9  # 시간할인율\n",
    "epsilon = 0.5  # ε-greedy 알고리즘 epsilon 초깃값\n",
    "v = np.nanmax(Q, axis=1)  # 각 상태마다 가치의 최댓값을 계산\n",
    "episode = 1\n",
    "\n",
    "for episode in range(1,51):\n",
    "    print(\"에피소드: \" + str(episode))\n",
    "\n",
    "    # ε 값을 조금씩 감소시킴\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0, episode)\n",
    "    print(\"Q-table :\\n\", Q)\n",
    "\n",
    "    # 상태가치의 변화\n",
    "    new_v = np.nanmax(Q, axis=1)  # 각 상태마다 행동가치의 최댓값을 계산\n",
    "    print(np.sum(np.abs(new_v - v)))  # 상태가치 함수의 변화를 출력\n",
    "    v = new_v\n",
    "\n",
    "    print(\"목표 지점에 이르기까지 걸린 단계 수는 \" + str(len(s_a_history) - 1) + \"단계입니다\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
